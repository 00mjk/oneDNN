<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.5"/>
<title>Intel(R) MKL-DNN: RNN int8 inference example</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)
   &#160;<span id="projectnumber">0.95.0</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.5 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">RNN int8 inference example </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This C++ API example demonstrates how to build an GNMT model inference For the encoder we use:</p>
<ul>
<li>one primitive for the bidirectional layer of the encoder</li>
<li>one primitive for all remaining unidirectional layers in the encoder For the decoder we use:</li>
<li>one primitive for the first iteration</li>
<li>one primitive for all subsequent iterations in the decoder. Note that in this example, this primitive computes the states in place.</li>
<li>the attention mechanism is implemented separately as there is no support for the context vectors in MKL-DNN yet</li>
</ul>
<div class="fragment"><div class="line"><span class="comment">/*******************************************************************************</span></div>
<div class="line"><span class="comment">* Copyright 2018-2019 Intel Corporation</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><span class="comment">* you may not use this file except in compliance with the License.</span></div>
<div class="line"><span class="comment">* You may obtain a copy of the License at</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><span class="comment">* See the License for the specific language governing permissions and</span></div>
<div class="line"><span class="comment">* limitations under the License.</span></div>
<div class="line"><span class="comment">*******************************************************************************/</span></div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#include &lt;assert.h&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#include &lt;cstring&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;math.h&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;numeric&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#include &quot;<a class="code" href="mkldnn_8hpp.html">mkldnn.hpp</a>&quot;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// MSVC doesn&#39;t support collapse clause in omp parallel</span></div>
<div class="line"><span class="preprocessor">#if defined(_MSC_VER) &amp;&amp; !defined(__clang__) &amp;&amp; !defined(__INTEL_COMPILER)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#define collapse(x)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line"><span class="keyword">using namespace </span>mkldnn;</div>
<div class="line"></div>
<div class="line"><span class="keyword">using</span> dim_t = mkldnn::memory::dim;</div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> dim_t batch = 64;</div>
<div class="line"><span class="keyword">const</span> dim_t src_seq_length_max = 25;</div>
<div class="line"><span class="keyword">const</span> dim_t tgt_seq_length_max = 27;</div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> dim_t feature_size = 1024;</div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> dim_t enc_bidir_n_layers = 1;</div>
<div class="line"><span class="keyword">const</span> dim_t enc_unidir_n_layers = 7;</div>
<div class="line"><span class="keyword">const</span> dim_t dec_n_layers = 8;</div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> lstm_n_gates = 4;</div>
<div class="line"></div>
<div class="line">std::vector&lt;int32_t&gt; weighted_src_layer(batch *feature_size, 1);</div>
<div class="line">std::vector&lt;float&gt; alignment_model(</div>
<div class="line">        src_seq_length_max *batch *feature_size, 1.0f);</div>
<div class="line">std::vector&lt;float&gt; alignments(src_seq_length_max *batch, 1.0f);</div>
<div class="line">std::vector&lt;float&gt; exp_sums(batch, 1.0f);</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> compute_weighted_annotations(<span class="keywordtype">float</span> *weighted_annotations,</div>
<div class="line">        dim_t src_seq_length_max, dim_t batch, dim_t feature_size,</div>
<div class="line">        <span class="keywordtype">float</span> *weights_annot, <span class="keywordtype">float</span> *annotations) {</div>
<div class="line">    <span class="comment">// annotations(aka enc_dst_layer) is (t, n, 2c)</span></div>
<div class="line">    <span class="comment">// weights_annot is (2c, c)</span></div>
<div class="line"></div>
<div class="line">    dim_t num_weighted_annotations = src_seq_length_max * batch;</div>
<div class="line">    <span class="comment">// annotation[i] = GEMM(weights_annot, enc_dst_layer[i]);</span></div>
<div class="line">    <a class="code" href="group__c__api__blas.html#ga870f4c4d4b48422fbcfe77fc308edc65">mkldnn_sgemm</a>(<span class="charliteral">&#39;N&#39;</span>, <span class="charliteral">&#39;N&#39;</span>, num_weighted_annotations, feature_size, feature_size,</div>
<div class="line">            1.f, annotations, feature_size, weights_annot, feature_size,</div>
<div class="line">            0.f, weighted_annotations, feature_size);</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> compute_sum_of_rows(</div>
<div class="line">        int8_t *a, dim_t rows, dim_t cols, int32_t *a_reduced) {</div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t i = 0; i &lt; cols; i++) {</div>
<div class="line">        a_reduced[i] = 0;</div>
<div class="line">        <span class="keywordflow">for</span> (dim_t j = 0; j &lt; rows; j++) {</div>
<div class="line">            a_reduced[i] += (int32_t)a[i * rows + j];</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> compute_attention(<span class="keywordtype">float</span> *context_vectors, dim_t src_seq_length_max,</div>
<div class="line">        dim_t batch, dim_t feature_size, int8_t *weights_src_layer,</div>
<div class="line">        <span class="keywordtype">float</span> weights_src_layer_scale, int32_t *compensation,</div>
<div class="line">        uint8_t *dec_src_layer, <span class="keywordtype">float</span> dec_src_layer_scale,</div>
<div class="line">        <span class="keywordtype">float</span> dec_src_layer_shift, uint8_t *annotations,</div>
<div class="line">        <span class="keywordtype">float</span> *weighted_annotations, <span class="keywordtype">float</span> *weights_alignments) {</div>
<div class="line">    <span class="comment">// dst_iter : (n, c) matrix</span></div>
<div class="line">    <span class="comment">// src_layer: (n, c) matrix</span></div>
<div class="line">    <span class="comment">// weighted_annotations (t, n, c)</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// weights_yi is (c, c)</span></div>
<div class="line">    <span class="comment">// weights_ai is (c, 1)</span></div>
<div class="line">    <span class="comment">// tmp[i] is (n, c)</span></div>
<div class="line">    <span class="comment">// a[i] is (n, 1)</span></div>
<div class="line">    <span class="comment">// p is (n, 1)</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// first we precompute the weighted_dec_src_layer</span></div>
<div class="line">    int32_t co = 0;</div>
<div class="line">    <a class="code" href="group__c__api__blas.html#gaea88ce38665acb91bdc2c99ba1bc8f36">mkldnn_gemm_u8s8s32</a>(<span class="charliteral">&#39;N&#39;</span>, <span class="charliteral">&#39;N&#39;</span>, <span class="charliteral">&#39;F&#39;</span>, batch, feature_size, feature_size,</div>
<div class="line">            1.f,</div>
<div class="line">            dec_src_layer, feature_size, 0,</div>
<div class="line">            weights_src_layer, feature_size, 0,</div>
<div class="line">            0.f, weighted_src_layer.data(), feature_size, &amp;co);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// then we compute the alignment model</span></div>
<div class="line">    <span class="keywordtype">float</span> *alignment_model_ptr = alignment_model.data();</div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for collapse(2)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t i = 0; i &lt; src_seq_length_max; i++) {</div>
<div class="line">        <span class="keywordflow">for</span> (dim_t j = 0; j &lt; batch; j++) {</div>
<div class="line">            <span class="keywordflow">for</span> (dim_t k = 0; k &lt; feature_size; k++) {</div>
<div class="line">                <span class="keywordtype">size_t</span> tnc_offset</div>
<div class="line">                        = i * batch * feature_size + j * feature_size + k;</div>
<div class="line">                alignment_model_ptr[tnc_offset] = tanhf(</div>
<div class="line">                        (<span class="keywordtype">float</span>)(weighted_src_layer.data()[j * feature_size + k]</div>
<div class="line">                                - dec_src_layer_shift * compensation[k])</div>
<div class="line">                                / (dec_src_layer_scale</div>
<div class="line">                                          * weights_src_layer_scale)</div>
<div class="line">                        + weighted_annotations[tnc_offset]);</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// gemv with alignments weights. the resulting alignments are in alignments</span></div>
<div class="line">    dim_t num_weighted_annotations = src_seq_length_max * batch;</div>
<div class="line">    <a class="code" href="group__c__api__blas.html#ga870f4c4d4b48422fbcfe77fc308edc65">mkldnn_sgemm</a>(<span class="charliteral">&#39;N&#39;</span>, <span class="charliteral">&#39;N&#39;</span>, num_weighted_annotations, 1, feature_size,</div>
<div class="line">            1.f, alignment_model_ptr, feature_size, weights_alignments, 1,</div>
<div class="line">            0.f, alignments.data(), 1);</div>
<div class="line"></div>
<div class="line"><span class="comment">// softmax on alignments. the resulting context weights are in alignments</span></div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t i = 0; i &lt; batch; i++)</div>
<div class="line">        exp_sums[i] = 0.0f;</div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for collapse(2)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t i = 0; i &lt; src_seq_length_max; i++) {</div>
<div class="line">        <span class="keywordflow">for</span> (dim_t j = 0; j &lt; batch; j++) {</div>
<div class="line">            alignments[i * batch + j] = expf(alignments[i * batch + j]);</div>
<div class="line">            exp_sums[j] += alignments[i * batch + j];</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for collapse(2)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t i = 0; i &lt; src_seq_length_max; i++)</div>
<div class="line">        <span class="keywordflow">for</span> (dim_t j = 0; j &lt; batch; j++)</div>
<div class="line">            alignments[i * batch + j] /= exp_sums[j];</div>
<div class="line"></div>
<div class="line"><span class="comment">// then we compute the context vectors</span></div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for collapse(2)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t i = 0; i &lt; batch; i++)</div>
<div class="line">        <span class="keywordflow">for</span> (dim_t j = 0; j &lt; feature_size; j++)</div>
<div class="line">            context_vectors[i * (feature_size + feature_size) + feature_size</div>
<div class="line">                    + j]</div>
<div class="line">                    = 0.0f;</div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for collapse(3)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t i = 0; i &lt; batch; i++)</div>
<div class="line">        <span class="keywordflow">for</span> (dim_t k = 0; k &lt; src_seq_length_max; k++)</div>
<div class="line">            <span class="keywordflow">for</span> (dim_t j = 0; j &lt; feature_size; j++)</div>
<div class="line">                context_vectors[i * (feature_size + feature_size) + feature_size</div>
<div class="line">                        + j]</div>
<div class="line">                        += alignments[k * batch + i]</div>
<div class="line">                        * (((float)annotations[j</div>
<div class="line">                                    + feature_size * (i + batch * k)]</div>
<div class="line">                                   - dec_src_layer_shift)</div>
<div class="line">                                  / dec_src_layer_scale);</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> copy_context(<span class="keywordtype">float</span> *src_iter, dim_t n_layers, dim_t batch,</div>
<div class="line">        dim_t feature_size) {</div>
<div class="line"><span class="comment">// we copy the context from the first layer to all other layers</span></div>
<div class="line"><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#pragma omp parallel for collapse(3)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span>    <span class="keywordflow">for</span> (dim_t k = 1; k &lt; n_layers; k++)</div>
<div class="line">        <span class="keywordflow">for</span> (dim_t j = 0; j &lt; batch; j++)</div>
<div class="line">            <span class="keywordflow">for</span> (dim_t i = 0; i &lt; feature_size; i++)</div>
<div class="line">                src_iter[(k * batch + j)</div>
<div class="line">                                * (feature_size + feature_size)</div>
<div class="line">                        + i]</div>
<div class="line">                        = src_iter[j * (feature_size + feature_size) + i];</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> simple_net() {</div>
<div class="line"><span class="comment">//[Initialize engine and stream]</span></div>
<div class="line">    <span class="keyword">auto</span> cpu_engine = <a class="code" href="group__cpp__api__enums.html#gga6d88ff11a07bae09a5c348d314c5d1d9aad1943a9fd6d3d7ee1e6af41a5b0d3e7">engine</a>(<a class="code" href="structmkldnn_1_1engine.html#a81bcf1ea92d7f98852a2c3e187825de6ad9747e2da342bdb995f6389533ad1a3d">engine::kind::cpu</a>, 0);</div>
<div class="line">    stream s(cpu_engine);</div>
<div class="line"><span class="comment">//[Initialize engine and stream]</span></div>
<div class="line"></div>
<div class="line"><span class="comment">//[declare net]</span></div>
<div class="line">    std::vector&lt;primitive&gt; encoder_net, decoder_net;</div>
<div class="line">    std::vector&lt;std::unordered_map&lt;int, memory&gt;&gt; encoder_net_args,</div>
<div class="line">            decoder_net_args;</div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; net_src(batch * src_seq_length_max * feature_size, 0.1f);</div>
<div class="line">    std::vector&lt;float&gt; net_dst(batch * tgt_seq_length_max * feature_size, 0.1f);</div>
<div class="line"><span class="comment">//[declare net]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// Quantization factors for fp32 data</span></div>
<div class="line"></div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> data_shift = 64.;</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> data_scale = 63.;</div>
<div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> weights_scale_mask = 3; <span class="comment">// 11 for last two dimensions of ldigo</span></div>
<div class="line">    <span class="comment">//[quantize]</span></div>
<div class="line">    std::vector&lt;float&gt; weights_scales(lstm_n_gates * feature_size);</div>
<div class="line">    <span class="comment">// assign halves of vector with arbitrary values</span></div>
<div class="line">    <span class="keyword">const</span> dim_t scales_half = lstm_n_gates * feature_size / 2;</div>
<div class="line">    std::fill(</div>
<div class="line">            weights_scales.begin(), weights_scales.begin() + scales_half, 30.f);</div>
<div class="line">    std::fill(weights_scales.begin() + scales_half + 1, weights_scales.end(),</div>
<div class="line">            65.5f);</div>
<div class="line">    <span class="comment">//[quantize]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[Initialize encoder memory]</span></div>
<div class="line">    memory::dims enc_bidir_src_layer_tz</div>
<div class="line">            = { src_seq_length_max, batch, feature_size };</div>
<div class="line">    memory::dims enc_bidir_weights_layer_tz = { enc_bidir_n_layers, 2,</div>
<div class="line">        feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_bidir_weights_iter_tz = { enc_bidir_n_layers, 2,</div>
<div class="line">        feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_bidir_bias_tz</div>
<div class="line">            = { enc_bidir_n_layers, 2, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_bidir_dst_layer_tz</div>
<div class="line">            = { src_seq_length_max, batch, 2 * feature_size };</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[Initialize encoder memory]</span></div>
<div class="line"></div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; user_enc_bidir_wei_layer(</div>
<div class="line">            enc_bidir_n_layers * 2 * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.3f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_bidir_wei_iter(</div>
<div class="line">            enc_bidir_n_layers * 2 * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.2f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_bidir_bias(</div>
<div class="line">            enc_bidir_n_layers * 2 * lstm_n_gates * feature_size, 1.0f);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[data memory creation]</span></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_src_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_src_layer_tz },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::tnc);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_layer_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_weights_layer_tz },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_iter_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_weights_iter_tz },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_bias_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_bias_tz },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldgo);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_src_layer_memory</div>
<div class="line">            = memory(user_enc_bidir_src_layer_md, cpu_engine, net_src.data());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_layer_memory = memory(user_enc_bidir_wei_layer_md,</div>
<div class="line">            cpu_engine, user_enc_bidir_wei_layer.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_iter_memory = memory(user_enc_bidir_wei_iter_md,</div>
<div class="line">            cpu_engine, user_enc_bidir_wei_iter.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_bias_memory = memory(</div>
<div class="line">            user_enc_bidir_bias_md, cpu_engine, user_enc_bidir_bias.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="comment">//[data memory creation]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[memory desc for RNN data]</span></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_src_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_src_layer_tz },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba077393852be20e37026d6281827662f2">memory::data_type::u8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_weights_layer_tz },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_iter_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_weights_iter_tz },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_dst_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_bidir_dst_layer_tz },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba077393852be20e37026d6281827662f2">memory::data_type::u8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line">    <span class="comment">//[memory desc for RNN data]</span></div>
<div class="line"></div>
<div class="line"></div>
<div class="line">    <span class="comment">// Check if int8 RNN is supported</span></div>
<div class="line">    <span class="keywordflow">try</span> {</div>
<div class="line">        <a class="code" href="structmkldnn_1_1lstm__forward_1_1desc.html">lstm_forward::desc</a> bi_layer_desc(<a class="code" href="group__cpp__api__enums.html#ggaeb087eae78f70a4d249a90aefa165cf8a3b9fad4f80d45368f856b5403198ac4c">prop_kind::forward_inference</a>,</div>
<div class="line">                rnn_direction::bidirectional_concat, enc_bidir_src_layer_md,</div>
<div class="line">                <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), enc_bidir_wei_layer_md,</div>
<div class="line">                enc_bidir_wei_iter_md, user_enc_bidir_bias_md,</div>
<div class="line">                enc_bidir_dst_layer_md, <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>());</div>
<div class="line">    } <span class="keywordflow">catch</span> (<a class="code" href="structmkldnn_1_1error.html">error</a> &amp;e) {</div>
<div class="line">        <span class="keywordflow">if</span> (e.status == <a class="code" href="group__c__api__types__generic.html#gga31866789b66acfb1c28b2f9bdd7bdfdda253b1d7923a77456485a19734788b220">mkldnn_unimplemented</a>) {</div>
<div class="line">            std::cerr</div>
<div class="line">                    &lt;&lt; <span class="stringliteral">&quot;Dependency on Intel(R) MKL version 2019u2 or newer is &quot;</span></div>
<div class="line">                       <span class="stringliteral">&quot;required for int8 RNN&quot;</span></div>
<div class="line">                    &lt;&lt; std::endl;</div>
<div class="line">        }</div>
<div class="line">        <span class="keywordflow">throw</span>;</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[create rnn desc]</span></div>
<div class="line">    <a class="code" href="structmkldnn_1_1lstm__forward_1_1desc.html">lstm_forward::desc</a> bi_layer_desc(<a class="code" href="group__cpp__api__enums.html#ggaeb087eae78f70a4d249a90aefa165cf8a3b9fad4f80d45368f856b5403198ac4c">prop_kind::forward_inference</a>,</div>
<div class="line">            rnn_direction::bidirectional_concat, enc_bidir_src_layer_md,</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), enc_bidir_wei_layer_md, enc_bidir_wei_iter_md,</div>
<div class="line">            user_enc_bidir_bias_md, enc_bidir_dst_layer_md, <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>());</div>
<div class="line">    <span class="comment">//[create rnn desc]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[RNN attri]</span></div>
<div class="line">    <a class="code" href="structmkldnn_1_1primitive__attr.html">primitive_attr</a> attr;</div>
<div class="line">    attr.<a class="code" href="structmkldnn_1_1primitive__attr.html#ae968faf51e83a2674464fbec6ebdb2f7">set_rnn_data_qparams</a>(data_scale, data_shift);</div>
<div class="line">    attr.<a class="code" href="structmkldnn_1_1primitive__attr.html#a01ad9f8c0b0518c2e77c8c9e4ab346f9">set_rnn_weights_qparams</a>(weights_scale_mask, weights_scales);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_prim_desc</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1lstm__forward_1_1primitive__desc.html">lstm_forward::primitive_desc</a>(bi_layer_desc, attr, cpu_engine);</div>
<div class="line">    <span class="comment">//[RNN attri]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[reorder input data]</span></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_src_layer_memory</div>
<div class="line">            = memory(enc_bidir_prim_desc.src_layer_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_src_layer_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_enc_bidir_src_layer_memory, enc_bidir_src_layer_memory, attr);</div>
<div class="line">    encoder_net.push_back(reorder(enc_bidir_src_layer_reorder_pd));</div>
<div class="line">    encoder_net_args.push_back(</div>
<div class="line">            { { MKLDNN_ARG_FROM, user_enc_bidir_src_layer_memory },</div>
<div class="line">                    { MKLDNN_ARG_TO, enc_bidir_src_layer_memory } });</div>
<div class="line">    <span class="comment">//[reorder input data]</span></div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_layer_memory</div>
<div class="line">            = memory(enc_bidir_prim_desc.weights_layer_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_layer_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_enc_bidir_wei_layer_memory, enc_bidir_wei_layer_memory, attr);</div>
<div class="line">    reorder(enc_bidir_wei_layer_reorder_pd)</div>
<div class="line">            .execute(s, user_enc_bidir_wei_layer_memory,</div>
<div class="line">                    enc_bidir_wei_layer_memory);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_iter_memory</div>
<div class="line">            = memory(enc_bidir_prim_desc.weights_iter_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_iter_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_enc_bidir_wei_iter_memory, enc_bidir_wei_iter_memory, attr);</div>
<div class="line">    reorder(enc_bidir_wei_iter_reorder_pd)</div>
<div class="line">            .execute(s, user_enc_bidir_wei_iter_memory,</div>
<div class="line">                    enc_bidir_wei_iter_memory);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_dst_layer_memory</div>
<div class="line">            = memory(enc_bidir_prim_desc.dst_layer_desc(), cpu_engine);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[push bi rnn to encoder net]</span></div>
<div class="line">    encoder_net.push_back(lstm_forward(enc_bidir_prim_desc));</div>
<div class="line">    encoder_net_args.push_back(</div>
<div class="line">            { { MKLDNN_ARG_SRC_LAYER, enc_bidir_src_layer_memory },</div>
<div class="line">                    { MKLDNN_ARG_WEIGHTS_LAYER, enc_bidir_wei_layer_memory },</div>
<div class="line">                    { MKLDNN_ARG_WEIGHTS_ITER, enc_bidir_wei_iter_memory },</div>
<div class="line">                    { MKLDNN_ARG_BIAS, user_enc_bidir_bias_memory },</div>
<div class="line">                    { MKLDNN_ARG_DST_LAYER, enc_bidir_dst_layer_memory } });</div>
<div class="line">    <span class="comment">//[push bi rnn to encoder net]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[first uni layer]</span></div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_first_wei_layer(</div>
<div class="line">            1 * 1 * 2 * feature_size * lstm_n_gates * feature_size, 0.3f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_first_wei_iter(</div>
<div class="line">            1 * 1 * feature_size * lstm_n_gates * feature_size, 0.2f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_first_bias(</div>
<div class="line">            1 * 1 * lstm_n_gates * feature_size, 1.0f);</div>
<div class="line">    <span class="comment">//[first uni layer]</span></div>
<div class="line"></div>
<div class="line">    memory::dims user_enc_uni_first_wei_layer_dims</div>
<div class="line">            = { 1, 1, 2 * feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_enc_uni_first_wei_iter_dims</div>
<div class="line">            = { 1, 1, feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_enc_uni_first_bias_dims</div>
<div class="line">            = { 1, 1, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_uni_first_dst_layer_dims</div>
<div class="line">            = { src_seq_length_max, batch, feature_size };</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_first_wei_layer_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_first_wei_layer_dims },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_first_wei_iter_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_first_wei_iter_dims },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_first_bias_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_first_bias_dims },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldgo);</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_first_wei_layer_memory</div>
<div class="line">            = memory(user_enc_uni_first_wei_layer_md, cpu_engine,</div>
<div class="line">                    user_enc_uni_first_wei_layer.data());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_first_wei_iter_memory</div>
<div class="line">            = memory(user_enc_uni_first_wei_iter_md, cpu_engine,</div>
<div class="line">                    user_enc_uni_first_wei_iter.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_first_bias_memory = memory(user_enc_uni_first_bias_md,</div>
<div class="line">            cpu_engine, user_enc_uni_first_bias.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_wei_layer_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_first_wei_layer_dims },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_wei_iter_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_first_wei_iter_dims },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_dst_layer_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_uni_first_dst_layer_dims },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba077393852be20e37026d6281827662f2">memory::data_type::u8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[create uni first]</span></div>
<div class="line"></div>
<div class="line">    <a class="code" href="structmkldnn_1_1lstm__forward_1_1desc.html">lstm_forward::desc</a> enc_uni_first_layer_desc(<a class="code" href="group__cpp__api__enums.html#ggaeb087eae78f70a4d249a90aefa165cf8a3b9fad4f80d45368f856b5403198ac4c">prop_kind::forward_inference</a>,</div>
<div class="line">            rnn_direction::unidirectional_left2right,</div>
<div class="line">            enc_bidir_dst_layer_md, <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), enc_uni_first_wei_layer_md,</div>
<div class="line">            enc_uni_first_wei_iter_md, user_enc_uni_first_bias_md,</div>
<div class="line">            enc_uni_first_dst_layer_md, <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>());</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_prim_desc = <a class="code" href="structmkldnn_1_1lstm__forward_1_1primitive__desc.html">lstm_forward::primitive_desc</a>(</div>
<div class="line">            enc_uni_first_layer_desc, attr, cpu_engine);</div>
<div class="line">    <span class="comment">//[create uni first]</span></div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_wei_layer_memory</div>
<div class="line">            = memory(enc_uni_first_prim_desc.weights_layer_desc(), cpu_engine);</div>
<div class="line">    reorder(user_enc_uni_first_wei_layer_memory, enc_uni_first_wei_layer_memory)</div>
<div class="line">            .execute(s, user_enc_uni_first_wei_layer_memory,</div>
<div class="line">                    enc_uni_first_wei_layer_memory);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_wei_iter_memory</div>
<div class="line">            = memory(enc_uni_first_prim_desc.weights_iter_desc(), cpu_engine);</div>
<div class="line">    reorder(user_enc_uni_first_wei_iter_memory, enc_uni_first_wei_iter_memory)</div>
<div class="line">            .execute(s, user_enc_uni_first_wei_iter_memory,</div>
<div class="line">                    enc_uni_first_wei_iter_memory);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_dst_layer_memory</div>
<div class="line">            = memory(enc_uni_first_prim_desc.dst_layer_desc(), cpu_engine);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[push first uni rnn to encoder net]</span></div>
<div class="line">    encoder_net.push_back(lstm_forward(enc_uni_first_prim_desc));</div>
<div class="line">    encoder_net_args.push_back({</div>
<div class="line">            { MKLDNN_ARG_SRC_LAYER, enc_bidir_dst_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_LAYER, enc_uni_first_wei_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_ITER, enc_uni_first_wei_iter_memory },</div>
<div class="line">            { MKLDNN_ARG_BIAS, user_enc_uni_first_bias_memory },</div>
<div class="line">            { MKLDNN_ARG_DST_LAYER, enc_uni_first_dst_layer_memory } });</div>
<div class="line">    <span class="comment">//[push first uni rnn to encoder net]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[remaining uni layers]</span></div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_wei_layer((enc_unidir_n_layers - 1) * 1</div>
<div class="line">                    * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.3f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_wei_iter((enc_unidir_n_layers - 1) * 1</div>
<div class="line">                    * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.2f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_bias(</div>
<div class="line">            (enc_unidir_n_layers - 1) * 1 * lstm_n_gates * feature_size, 1.0f);</div>
<div class="line">    <span class="comment">//[remaining uni layers]</span></div>
<div class="line"></div>
<div class="line">    memory::dims user_enc_uni_wei_layer_dims = { (enc_unidir_n_layers - 1), 1,</div>
<div class="line">        feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_enc_uni_wei_iter_dims = { (enc_unidir_n_layers - 1), 1,</div>
<div class="line">        feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_enc_uni_bias_dims</div>
<div class="line">            = { (enc_unidir_n_layers - 1), 1, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_dst_layer_dims</div>
<div class="line">            = { src_seq_length_max, batch, feature_size };</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_wei_layer_md</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_wei_layer_dims },</div>
<div class="line">                    <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_wei_iter_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_wei_iter_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_bias_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_bias_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldgo);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_wei_layer_memory = memory(user_enc_uni_wei_layer_md,</div>
<div class="line">            cpu_engine, user_enc_uni_wei_layer.data());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_wei_iter_memory = memory(</div>
<div class="line">            user_enc_uni_wei_iter_md, cpu_engine, user_enc_uni_wei_iter.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_uni_bias_memory = memory(</div>
<div class="line">            user_enc_uni_bias_md, cpu_engine, user_enc_uni_bias.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_wei_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_wei_layer_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line">    <span class="keyword">auto</span> enc_uni_wei_iter_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_enc_uni_wei_iter_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line">    <span class="keyword">auto</span> enc_dst_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ enc_dst_layer_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[create uni rnn]</span></div>
<div class="line"></div>
<div class="line">    <a class="code" href="structmkldnn_1_1lstm__forward_1_1desc.html">lstm_forward::desc</a> enc_uni_layer_desc(<a class="code" href="group__cpp__api__enums.html#ggaeb087eae78f70a4d249a90aefa165cf8a3b9fad4f80d45368f856b5403198ac4c">prop_kind::forward_inference</a>,</div>
<div class="line">            rnn_direction::unidirectional_left2right,</div>
<div class="line">            enc_uni_first_dst_layer_md, <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), enc_uni_wei_layer_md,</div>
<div class="line">            enc_uni_wei_iter_md, user_enc_uni_bias_md, enc_dst_layer_md,</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>(), <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>());</div>
<div class="line">    <span class="keyword">auto</span> enc_uni_prim_desc</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1lstm__forward_1_1primitive__desc.html">lstm_forward::primitive_desc</a>(enc_uni_layer_desc, attr, cpu_engine);</div>
<div class="line">    <span class="comment">//[create uni rnn]</span></div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_wei_layer_memory</div>
<div class="line">            = memory(enc_uni_prim_desc.weights_layer_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> enc_uni_wei_layer_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_enc_uni_wei_layer_memory, enc_uni_wei_layer_memory, attr);</div>
<div class="line">    reorder(enc_uni_wei_layer_reorder_pd)</div>
<div class="line">            .execute(</div>
<div class="line">                    s, user_enc_uni_wei_layer_memory, enc_uni_wei_layer_memory);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_wei_iter_memory</div>
<div class="line">            = memory(enc_uni_prim_desc.weights_iter_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> enc_uni_wei_iter_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_enc_uni_wei_iter_memory, enc_uni_wei_iter_memory, attr);</div>
<div class="line">    reorder(enc_uni_wei_iter_reorder_pd)</div>
<div class="line">            .execute(s, user_enc_uni_wei_iter_memory, enc_uni_wei_iter_memory);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_dst_layer_memory</div>
<div class="line">            = memory(enc_uni_prim_desc.dst_layer_desc(), cpu_engine);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[push uni rnn to encoder net]</span></div>
<div class="line">    encoder_net.push_back(lstm_forward(enc_uni_prim_desc));</div>
<div class="line">    encoder_net_args.push_back({</div>
<div class="line">            { MKLDNN_ARG_SRC_LAYER, enc_uni_first_dst_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_LAYER, enc_uni_wei_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_ITER, enc_uni_wei_iter_memory },</div>
<div class="line">            { MKLDNN_ARG_BIAS, user_enc_uni_bias_memory },</div>
<div class="line">            { MKLDNN_ARG_DST_LAYER, enc_dst_layer_memory } });</div>
<div class="line">    <span class="comment">//[push uni rnn to encoder net]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[dec mem dim]</span></div>
<div class="line">    std::vector&lt;float&gt; user_dec_wei_layer(</div>
<div class="line">            dec_n_layers * 1 * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.2f);</div>
<div class="line">    std::vector&lt;float&gt; user_dec_wei_iter(dec_n_layers * 1</div>
<div class="line">                    * (feature_size + feature_size) * lstm_n_gates</div>
<div class="line">                    * feature_size,</div>
<div class="line">            0.3f);</div>
<div class="line">    std::vector&lt;float&gt; user_dec_bias(</div>
<div class="line">            dec_n_layers * 1 * lstm_n_gates * feature_size, 1.0f);</div>
<div class="line">    std::vector&lt;int8_t&gt; user_weights_attention_src_layer(</div>
<div class="line">            feature_size * feature_size, 1);</div>
<div class="line">    <span class="keywordtype">float</span> weights_attention_scale = 127.;</div>
<div class="line">    std::vector&lt;float&gt; user_weights_annotation(</div>
<div class="line">            feature_size * feature_size, 1.0f);</div>
<div class="line">    std::vector&lt;float&gt; user_weights_alignments(feature_size, 1.0f);</div>
<div class="line">    <span class="comment">// Buffer to store decoder output for all iterations</span></div>
<div class="line">    std::vector&lt;uint8_t&gt; dec_dst(tgt_seq_length_max * batch * feature_size, 0);</div>
<div class="line"></div>
<div class="line">    memory::dims user_dec_wei_layer_dims</div>
<div class="line">            = { dec_n_layers, 1, feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_dec_wei_iter_dims = { dec_n_layers, 1,</div>
<div class="line">        feature_size + feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_dec_bias_dims</div>
<div class="line">            = { dec_n_layers, 1, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims dec_src_layer_dims = { 1, batch, feature_size };</div>
<div class="line">    memory::dims dec_dst_layer_dims = { 1, batch, feature_size };</div>
<div class="line">    memory::dims dec_dst_iter_c_dims = { dec_n_layers, 1, batch,</div>
<div class="line">        feature_size };</div>
<div class="line">    <span class="comment">//[dec mem dim]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// We will use the same memory for dec_src_iter and dec_dst_iter</span></div>
<div class="line">    <span class="comment">// However, dec_src_iter has a context vector but not</span></div>
<div class="line">    <span class="comment">// dec_dst_iter.</span></div>
<div class="line">    <span class="comment">// To resolve this we will create one memory that holds the</span></div>
<div class="line">    <span class="comment">// context vector as well as the both the hidden and cell states.</span></div>
<div class="line">    <span class="comment">// For the dst_iter, we will use a view on this memory.</span></div>
<div class="line">    <span class="comment">// Note that the cell state will be padded by</span></div>
<div class="line">    <span class="comment">// feature_size values. However, we do not compute or</span></div>
<div class="line">    <span class="comment">// access those.</span></div>
<div class="line"><span class="comment"></span>    <span class="comment">//[noctx mem dim]</span></div>
<div class="line">    memory::dims dec_dst_iter_dims = { dec_n_layers, 1, batch,</div>
<div class="line">        feature_size + feature_size };</div>
<div class="line">    memory::dims dec_dst_iter_noctx_dims</div>
<div class="line">            = { dec_n_layers, 1, batch, feature_size };</div>
<div class="line">    <span class="comment">//[noctx mem dim]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[dec mem desc]</span></div>
<div class="line">    <span class="keyword">auto</span> user_dec_wei_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_dec_wei_layer_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_dec_wei_iter_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_dec_wei_iter_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_dec_bias_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_dec_bias_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldgo);</div>
<div class="line">    <span class="keyword">auto</span> dec_src_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ dec_src_layer_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba077393852be20e37026d6281827662f2">memory::data_type::u8</a>, memory::format_tag::tnc);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ dec_dst_layer_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba077393852be20e37026d6281827662f2">memory::data_type::u8</a>, memory::format_tag::tnc);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ dec_dst_iter_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldnc);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_c_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ dec_dst_iter_c_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, memory::format_tag::ldnc);</div>
<div class="line">    <span class="comment">//[dec mem desc]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">//[create dec memory]</span></div>
<div class="line">    <span class="keyword">auto</span> user_dec_wei_layer_memory = memory(</div>
<div class="line">            user_dec_wei_layer_md, cpu_engine, user_dec_wei_layer.data());</div>
<div class="line">    <span class="keyword">auto</span> user_dec_wei_iter_memory = memory(</div>
<div class="line">            user_dec_wei_iter_md, cpu_engine, user_dec_wei_iter.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="keyword">auto</span> user_dec_bias_memory</div>
<div class="line">            = memory(user_dec_bias_md, cpu_engine, user_dec_bias.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="keyword">auto</span> dec_src_layer_memory = memory(dec_src_layer_md, cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_layer_memory</div>
<div class="line">            = memory(dec_dst_layer_md, cpu_engine, dec_dst.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#abeddf8909e2b4af626153c88da9f8b37">data</a>());</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_c_memory = memory(dec_dst_iter_c_md, cpu_engine);</div>
<div class="line">    <span class="comment">//[create dec memory]</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// Create memory descriptors for RNN data w/o specified layout</span></div>
<div class="line">    <span class="keyword">auto</span> dec_wei_layer_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_dec_wei_layer_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line">    <span class="keyword">auto</span> dec_wei_iter_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ user_dec_wei_iter_dims },</div>
<div class="line">            <a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57ba3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, <a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ceda100b8cad7cf2a56f6df78f171f97a1ec">memory::format_tag::any</a>);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[create noctx mem]</span></div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_memory = memory(dec_dst_iter_md, cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_noctx_md = dec_dst_iter_md.<a class="code" href="structmkldnn_1_1memory_1_1desc.html#a58ccb996eecfe7357b616f47953ff3ad">submemory_desc</a>(</div>
<div class="line">            dec_dst_iter_noctx_dims, { 0, 0, 0, 0, 0 });</div>
<div class="line">    <span class="comment">//[create noctx mem]</span></div>
<div class="line"></div>
<div class="line">    <a class="code" href="structmkldnn_1_1lstm__forward_1_1desc.html">lstm_forward::desc</a> dec_ctx_desc(<a class="code" href="group__cpp__api__enums.html#ggaeb087eae78f70a4d249a90aefa165cf8a3b9fad4f80d45368f856b5403198ac4c">prop_kind::forward_inference</a>,</div>
<div class="line">            rnn_direction::unidirectional_left2right, dec_src_layer_md,</div>
<div class="line">            dec_dst_iter_md, dec_dst_iter_c_md, dec_wei_layer_md,</div>
<div class="line">            dec_wei_iter_md, user_dec_bias_md, dec_dst_layer_md,</div>
<div class="line">            dec_dst_iter_noctx_md, dec_dst_iter_c_md);</div>
<div class="line">    <span class="keyword">auto</span> dec_ctx_prim_desc</div>
<div class="line">            = <a class="code" href="structmkldnn_1_1lstm__forward_1_1primitive__desc.html">lstm_forward::primitive_desc</a>(dec_ctx_desc, attr, cpu_engine);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//[dec reorder]</span></div>
<div class="line">    <span class="keyword">auto</span> dec_wei_layer_memory</div>
<div class="line">            = memory(dec_ctx_prim_desc.weights_layer_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> dec_wei_layer_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_dec_wei_layer_memory, dec_wei_layer_memory, attr);</div>
<div class="line">    reorder(dec_wei_layer_reorder_pd)</div>
<div class="line">            .execute(s, user_dec_wei_layer_memory, dec_wei_layer_memory);</div>
<div class="line">    <span class="comment">//[dec reorder]</span></div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> dec_wei_iter_memory</div>
<div class="line">            = memory(dec_ctx_prim_desc.weights_iter_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> dec_wei_iter_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_dec_wei_iter_memory, dec_wei_iter_memory, attr);</div>
<div class="line">    reorder(dec_wei_iter_reorder_pd)</div>
<div class="line">            .execute(s, user_dec_wei_iter_memory, dec_wei_iter_memory);</div>
<div class="line"></div>
<div class="line">    decoder_net.push_back(lstm_forward(dec_ctx_prim_desc));</div>
<div class="line">    decoder_net_args.push_back({ { MKLDNN_ARG_SRC_LAYER, dec_src_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_SRC_ITER, dec_dst_iter_memory },</div>
<div class="line">            { MKLDNN_ARG_SRC_ITER_C, dec_dst_iter_c_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_LAYER, dec_wei_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_ITER, dec_wei_iter_memory },</div>
<div class="line">            { MKLDNN_ARG_BIAS, user_dec_bias_memory },</div>
<div class="line">            { MKLDNN_ARG_DST_LAYER, dec_dst_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_DST_ITER, dec_dst_iter_memory },</div>
<div class="line">            { MKLDNN_ARG_DST_ITER_C, dec_dst_iter_c_memory } });</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Allocating temporary buffers for attention mechanism</span></div>
<div class="line">    std::vector&lt;float&gt; weighted_annotations(</div>
<div class="line">            src_seq_length_max * batch * feature_size, 1.0f);</div>
<div class="line">    std::vector&lt;int32_t&gt; weights_attention_sum_rows(feature_size, 1);</div>
<div class="line"></div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> execute = [&amp;]() {</div>
<div class="line">        assert(encoder_net.size() == encoder_net_args.size()</div>
<div class="line">                &amp;&amp; <span class="stringliteral">&quot;something is missing&quot;</span>);</div>
<div class="line">        <span class="comment">//[run enc]</span></div>
<div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> p = 0; p &lt; encoder_net.size(); ++p)</div>
<div class="line">            encoder_net.at(p).execute(s, encoder_net_args.at(p));</div>
<div class="line">        <span class="comment">//[run enc]</span></div>
<div class="line"></div>
<div class="line">        <span class="comment">// compute the weighted annotations once before the decoder</span></div>
<div class="line"><span class="comment"></span>        <span class="comment">//[weight ano]</span></div>
<div class="line">        compute_weighted_annotations(weighted_annotations.data(),</div>
<div class="line">                src_seq_length_max, batch, feature_size,</div>
<div class="line">                user_weights_annotation.data(),</div>
<div class="line">                (<span class="keywordtype">float</span> *)enc_dst_layer_memory.get_data_handle());</div>
<div class="line">        <span class="comment">//[weight ano]</span></div>
<div class="line"><span class="comment"></span>        <span class="comment">//[s8u8s32]</span></div>
<div class="line">        compute_sum_of_rows(user_weights_attention_src_layer.data(),</div>
<div class="line">                feature_size, feature_size, weights_attention_sum_rows.data());</div>
<div class="line">        <span class="comment">//[s8u8s32]</span></div>
<div class="line"></div>
<div class="line">        <span class="comment">//[init src_layer]</span></div>
<div class="line">        memset(dec_src_layer_memory.<a class="code" href="structmkldnn_1_1memory.html#a07d67b26cdd115092f8574cc000f96fc">get_data_handle</a>(), 0,</div>
<div class="line">                dec_src_layer_memory.<a class="code" href="structmkldnn_1_1memory.html#aad39e92bb09b189c1ba6353dd631fb80">get_desc</a>().<a class="code" href="structmkldnn_1_1memory_1_1desc.html#a273a35ba51f1ce0185e1703cc96d9dec">get_size</a>());</div>
<div class="line">        <span class="comment">//[init src_layer]</span></div>
<div class="line"></div>
<div class="line">        <span class="keywordflow">for</span> (dim_t i = 0; i &lt; tgt_seq_length_max; i++) {</div>
<div class="line">            uint8_t *src_att_layer_handle</div>
<div class="line">                    = (uint8_t *)dec_src_layer_memory.<a class="code" href="structmkldnn_1_1memory.html#a07d67b26cdd115092f8574cc000f96fc">get_data_handle</a>();</div>
<div class="line">            <span class="keywordtype">float</span> *src_att_iter_handle</div>
<div class="line">                    = (<span class="keywordtype">float</span> *)dec_dst_iter_memory.get_data_handle();</div>
<div class="line"></div>
<div class="line">            <span class="comment">//[att ctx]</span></div>
<div class="line">            compute_attention(src_att_iter_handle, src_seq_length_max, batch,</div>
<div class="line">                    feature_size, user_weights_attention_src_layer.data(),</div>
<div class="line">                    weights_attention_scale, weights_attention_sum_rows.data(),</div>
<div class="line">                    src_att_layer_handle, data_scale, data_shift,</div>
<div class="line">                    (uint8_t *)enc_bidir_dst_layer_memory.get_data_handle(),</div>
<div class="line">                    weighted_annotations.data(),</div>
<div class="line">                    user_weights_alignments.data());</div>
<div class="line">            <span class="comment">//[att ctx]</span></div>
<div class="line"></div>
<div class="line">            <span class="comment">//[cp ctx]</span></div>
<div class="line">            copy_context(src_att_iter_handle, dec_n_layers, batch,</div>
<div class="line">                    feature_size);</div>
<div class="line">            <span class="comment">//[cp ctx]</span></div>
<div class="line"></div>
<div class="line">            assert(decoder_net.size() == decoder_net_args.size()</div>
<div class="line">                    &amp;&amp; <span class="stringliteral">&quot;something is missing&quot;</span>);</div>
<div class="line">            <span class="comment">//[run dec iter]</span></div>
<div class="line">            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> p = 0; p &lt; decoder_net.size(); ++p)</div>
<div class="line">                decoder_net.at(p).execute(s, decoder_net_args.at(p));</div>
<div class="line">            <span class="comment">//[run dec iter]</span></div>
<div class="line"></div>
<div class="line">            <span class="comment">//[set handle]</span></div>
<div class="line">            <span class="keyword">auto</span> dst_layer_handle</div>
<div class="line">                    = (uint8_t *)dec_dst_layer_memory.get_data_handle();</div>
<div class="line">            dec_src_layer_memory.set_data_handle(dst_layer_handle);</div>
<div class="line">            dec_dst_layer_memory.set_data_handle(</div>
<div class="line">                    dst_layer_handle + batch * feature_size);</div>
<div class="line">            <span class="comment">//[set handle]</span></div>
<div class="line">        }</div>
<div class="line"></div>
<div class="line">    };</div>
<div class="line"></div>
<div class="line">    execute();</div>
<div class="line">    s.<a class="code" href="structmkldnn_1_1stream.html#a48181ce0f5eb3bcd75778b5aa8866df6">wait</a>();</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> **argv) {</div>
<div class="line">    <span class="keywordflow">try</span> {</div>
<div class="line">        simple_net();</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;ok\n&quot;</span>;</div>
<div class="line">    } <span class="keywordflow">catch</span> (<a class="code" href="structmkldnn_1_1error.html">error</a> &amp;e) {</div>
<div class="line">        std::cerr &lt;&lt; <span class="stringliteral">&quot;status: &quot;</span> &lt;&lt; e.status &lt;&lt; std::endl;</div>
<div class="line">        std::cerr &lt;&lt; <span class="stringliteral">&quot;message: &quot;</span> &lt;&lt; e.message &lt;&lt; std::endl;</div>
<div class="line">    }</div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Initialize a CPU engine and stream. The last parameter in the call represents the index of the engine. </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> cpu_engine = engine(engine::kind::cpu, 0);</div>
<div class="line">    stream s(cpu_engine);</div>
</div><!-- fragment --><p>Declare encoder net and decoder net </p>
<div class="fragment"><div class="line">    std::vector&lt;primitive&gt; encoder_net, decoder_net;</div>
<div class="line">    std::vector&lt;std::unordered_map&lt;int, memory&gt;&gt; encoder_net_args,</div>
<div class="line">            decoder_net_args;</div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; net_src(batch * src_seq_length_max * feature_size, 0.1f);</div>
<div class="line">    std::vector&lt;float&gt; net_dst(batch * tgt_seq_length_max * feature_size, 0.1f);</div>
</div><!-- fragment --><p>Quantization factors for fp32 data </p>
<div class="fragment"><div class="line">    std::vector&lt;float&gt; weights_scales(lstm_n_gates * feature_size);</div>
<div class="line">    <span class="comment">// assign halves of vector with arbitrary values</span></div>
<div class="line">    <span class="keyword">const</span> dim_t scales_half = lstm_n_gates * feature_size / 2;</div>
<div class="line">    std::fill(</div>
<div class="line">            weights_scales.begin(), weights_scales.begin() + scales_half, 30.f);</div>
<div class="line">    std::fill(weights_scales.begin() + scales_half + 1, weights_scales.end(),</div>
<div class="line">            65.5f);</div>
</div><!-- fragment --><p><b>Encoder</b></p>
<p>Initialize Encoder Memory </p>
<div class="fragment"><div class="line">    memory::dims enc_bidir_src_layer_tz</div>
<div class="line">            = { src_seq_length_max, batch, feature_size };</div>
<div class="line">    memory::dims enc_bidir_weights_layer_tz = { enc_bidir_n_layers, 2,</div>
<div class="line">        feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_bidir_weights_iter_tz = { enc_bidir_n_layers, 2,</div>
<div class="line">        feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_bidir_bias_tz</div>
<div class="line">            = { enc_bidir_n_layers, 2, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims enc_bidir_dst_layer_tz</div>
<div class="line">            = { src_seq_length_max, batch, 2 * feature_size };</div>
<div class="line"></div>
</div><!-- fragment --><p>Encoder: 1 bidirectional layer and 7 unidirectional layers</p>
<p>Create the memory for user data </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> user_enc_bidir_src_layer_md = memory::desc({ enc_bidir_src_layer_tz },</div>
<div class="line">            memory::data_type::f32, memory::format_tag::tnc);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_layer_md</div>
<div class="line">            = memory::desc({ enc_bidir_weights_layer_tz },</div>
<div class="line">                    memory::data_type::f32, memory::format_tag::ldigo);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_iter_md</div>
<div class="line">            = memory::desc({ enc_bidir_weights_iter_tz },</div>
<div class="line">                    memory::data_type::f32, memory::format_tag::ldigo);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_bias_md = memory::desc({ enc_bidir_bias_tz },</div>
<div class="line">            memory::data_type::f32, memory::format_tag::ldgo);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_src_layer_memory</div>
<div class="line">            = memory(user_enc_bidir_src_layer_md, cpu_engine, net_src.data());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_layer_memory = memory(user_enc_bidir_wei_layer_md,</div>
<div class="line">            cpu_engine, user_enc_bidir_wei_layer.data());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_iter_memory = memory(user_enc_bidir_wei_iter_md,</div>
<div class="line">            cpu_engine, user_enc_bidir_wei_iter.data());</div>
<div class="line">    <span class="keyword">auto</span> user_enc_bidir_bias_memory = memory(</div>
<div class="line">            user_enc_bidir_bias_md, cpu_engine, user_enc_bidir_bias.data());</div>
</div><!-- fragment --><p>Create memory descriptors for RNN data w/o specified layout </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> enc_bidir_src_layer_md = memory::desc({ enc_bidir_src_layer_tz },</div>
<div class="line">            memory::data_type::u8, memory::format_tag::any);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_layer_md = memory::desc({ enc_bidir_weights_layer_tz },</div>
<div class="line">            memory::data_type::s8, memory::format_tag::any);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_wei_iter_md = memory::desc({ enc_bidir_weights_iter_tz },</div>
<div class="line">            memory::data_type::s8, memory::format_tag::any);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_dst_layer_md = memory::desc({ enc_bidir_dst_layer_tz },</div>
<div class="line">            memory::data_type::u8, memory::format_tag::any);</div>
</div><!-- fragment --><p>Create bidirectional RNN</p>
<div class="fragment"><div class="line">    lstm_forward::desc bi_layer_desc(prop_kind::forward_inference,</div>
<div class="line">            rnn_direction::bidirectional_concat, enc_bidir_src_layer_md,</div>
<div class="line">            memory::desc(), memory::desc(), enc_bidir_wei_layer_md, enc_bidir_wei_iter_md,</div>
<div class="line">            user_enc_bidir_bias_md, enc_bidir_dst_layer_md, memory::desc(), memory::desc());</div>
</div><!-- fragment --><p>Define RNN attributes that store quantization parameters </p>
<div class="fragment"><div class="line">    primitive_attr attr;</div>
<div class="line">    attr.<a class="code" href="structmkldnn_1_1primitive__attr.html#ae968faf51e83a2674464fbec6ebdb2f7">set_rnn_data_qparams</a>(data_scale, data_shift);</div>
<div class="line">    attr.set_rnn_weights_qparams(weights_scale_mask, weights_scales);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_prim_desc</div>
<div class="line">            = lstm_forward::primitive_desc(bi_layer_desc, attr, cpu_engine);</div>
</div><!-- fragment --><p>Create memory for input data and use reorders to quantize values to int8 NOTE: same attributes are used when creating RNN primitive and reorders </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> enc_bidir_src_layer_memory</div>
<div class="line">            = memory(enc_bidir_prim_desc.src_layer_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> enc_bidir_src_layer_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_enc_bidir_src_layer_memory, enc_bidir_src_layer_memory, attr);</div>
<div class="line">    encoder_net.push_back(reorder(enc_bidir_src_layer_reorder_pd));</div>
<div class="line">    encoder_net_args.push_back(</div>
<div class="line">            { { MKLDNN_ARG_FROM, user_enc_bidir_src_layer_memory },</div>
<div class="line">                    { MKLDNN_ARG_TO, enc_bidir_src_layer_memory } });</div>
</div><!-- fragment --><p>Encoder : add the bidirectional rnn primitive with related arguments into encoder_net </p>
<div class="fragment"><div class="line">    encoder_net.push_back(lstm_forward(enc_bidir_prim_desc));</div>
<div class="line">    encoder_net_args.push_back(</div>
<div class="line">            { { MKLDNN_ARG_SRC_LAYER, enc_bidir_src_layer_memory },</div>
<div class="line">                    { MKLDNN_ARG_WEIGHTS_LAYER, enc_bidir_wei_layer_memory },</div>
<div class="line">                    { MKLDNN_ARG_WEIGHTS_ITER, enc_bidir_wei_iter_memory },</div>
<div class="line">                    { MKLDNN_ARG_BIAS, user_enc_bidir_bias_memory },</div>
<div class="line">                    { MKLDNN_ARG_DST_LAYER, enc_bidir_dst_layer_memory } });</div>
</div><!-- fragment --><p>Encoder: unidirectional layers</p>
<p>First unidirectinal layer scales 2 * feature_size output of bidirectional layer to feature_size output </p>
<div class="fragment"><div class="line">    std::vector&lt;float&gt; user_enc_uni_first_wei_layer(</div>
<div class="line">            1 * 1 * 2 * feature_size * lstm_n_gates * feature_size, 0.3f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_first_wei_iter(</div>
<div class="line">            1 * 1 * feature_size * lstm_n_gates * feature_size, 0.2f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_first_bias(</div>
<div class="line">            1 * 1 * lstm_n_gates * feature_size, 1.0f);</div>
</div><!-- fragment --><p>Encoder : Create unidirection RNN for first cell </p>
<div class="fragment"><div class="line"></div>
<div class="line">    lstm_forward::desc enc_uni_first_layer_desc(prop_kind::forward_inference,</div>
<div class="line">            rnn_direction::unidirectional_left2right,</div>
<div class="line">            enc_bidir_dst_layer_md, memory::desc(), memory::desc(), enc_uni_first_wei_layer_md,</div>
<div class="line">            enc_uni_first_wei_iter_md, user_enc_uni_first_bias_md,</div>
<div class="line">            enc_uni_first_dst_layer_md, memory::desc(), memory::desc());</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> enc_uni_first_prim_desc = lstm_forward::primitive_desc(</div>
<div class="line">            enc_uni_first_layer_desc, attr, cpu_engine);</div>
</div><!-- fragment --><p>Encoder : add the first unidirectional rnn primitive with related arguments into encoder_net </p>
<div class="fragment"><div class="line">    encoder_net.push_back(lstm_forward(enc_uni_first_prim_desc));</div>
<div class="line">    encoder_net_args.push_back({</div>
<div class="line">            { MKLDNN_ARG_SRC_LAYER, enc_bidir_dst_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_LAYER, enc_uni_first_wei_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_ITER, enc_uni_first_wei_iter_memory },</div>
<div class="line">            { MKLDNN_ARG_BIAS, user_enc_uni_first_bias_memory },</div>
<div class="line">            { MKLDNN_ARG_DST_LAYER, enc_uni_first_dst_layer_memory } });</div>
</div><!-- fragment --><p>Encoder : Remaining unidirectional layers </p>
<div class="fragment"><div class="line">    std::vector&lt;float&gt; user_enc_uni_wei_layer((enc_unidir_n_layers - 1) * 1</div>
<div class="line">                    * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.3f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_wei_iter((enc_unidir_n_layers - 1) * 1</div>
<div class="line">                    * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.2f);</div>
<div class="line">    std::vector&lt;float&gt; user_enc_uni_bias(</div>
<div class="line">            (enc_unidir_n_layers - 1) * 1 * lstm_n_gates * feature_size, 1.0f);</div>
</div><!-- fragment --><p>Encoder : Create unidirection RNN cell </p>
<div class="fragment"><div class="line"></div>
<div class="line">    lstm_forward::desc enc_uni_layer_desc(prop_kind::forward_inference,</div>
<div class="line">            rnn_direction::unidirectional_left2right,</div>
<div class="line">            enc_uni_first_dst_layer_md, memory::desc(), memory::desc(), enc_uni_wei_layer_md,</div>
<div class="line">            enc_uni_wei_iter_md, user_enc_uni_bias_md, enc_dst_layer_md,</div>
<div class="line">            memory::desc(), memory::desc());</div>
<div class="line">    <span class="keyword">auto</span> enc_uni_prim_desc</div>
<div class="line">            = lstm_forward::primitive_desc(enc_uni_layer_desc, attr, cpu_engine);</div>
</div><!-- fragment --><p>Encoder : add the unidirectional rnn primitive with related arguments into encoder_net </p>
<div class="fragment"><div class="line">    encoder_net.push_back(lstm_forward(enc_uni_prim_desc));</div>
<div class="line">    encoder_net_args.push_back({</div>
<div class="line">            { MKLDNN_ARG_SRC_LAYER, enc_uni_first_dst_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_LAYER, enc_uni_wei_layer_memory },</div>
<div class="line">            { MKLDNN_ARG_WEIGHTS_ITER, enc_uni_wei_iter_memory },</div>
<div class="line">            { MKLDNN_ARG_BIAS, user_enc_uni_bias_memory },</div>
<div class="line">            { MKLDNN_ARG_DST_LAYER, enc_dst_layer_memory } });</div>
</div><!-- fragment --><p><b>Decoder with attention mechanism</b></p>
<p>Decoder : declare memory dimensions </p>
<div class="fragment"><div class="line">    std::vector&lt;float&gt; user_dec_wei_layer(</div>
<div class="line">            dec_n_layers * 1 * feature_size * lstm_n_gates * feature_size,</div>
<div class="line">            0.2f);</div>
<div class="line">    std::vector&lt;float&gt; user_dec_wei_iter(dec_n_layers * 1</div>
<div class="line">                    * (feature_size + feature_size) * lstm_n_gates</div>
<div class="line">                    * feature_size,</div>
<div class="line">            0.3f);</div>
<div class="line">    std::vector&lt;float&gt; user_dec_bias(</div>
<div class="line">            dec_n_layers * 1 * lstm_n_gates * feature_size, 1.0f);</div>
<div class="line">    std::vector&lt;int8_t&gt; user_weights_attention_src_layer(</div>
<div class="line">            feature_size * feature_size, 1);</div>
<div class="line">    <span class="keywordtype">float</span> weights_attention_scale = 127.;</div>
<div class="line">    std::vector&lt;float&gt; user_weights_annotation(</div>
<div class="line">            feature_size * feature_size, 1.0f);</div>
<div class="line">    std::vector&lt;float&gt; user_weights_alignments(feature_size, 1.0f);</div>
<div class="line">    <span class="comment">// Buffer to store decoder output for all iterations</span></div>
<div class="line">    std::vector&lt;uint8_t&gt; dec_dst(tgt_seq_length_max * batch * feature_size, 0);</div>
<div class="line"></div>
<div class="line">    memory::dims user_dec_wei_layer_dims</div>
<div class="line">            = { dec_n_layers, 1, feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_dec_wei_iter_dims = { dec_n_layers, 1,</div>
<div class="line">        feature_size + feature_size, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims user_dec_bias_dims</div>
<div class="line">            = { dec_n_layers, 1, lstm_n_gates, feature_size };</div>
<div class="line">    memory::dims dec_src_layer_dims = { 1, batch, feature_size };</div>
<div class="line">    memory::dims dec_dst_layer_dims = { 1, batch, feature_size };</div>
<div class="line">    memory::dims dec_dst_iter_c_dims = { dec_n_layers, 1, batch,</div>
<div class="line">        feature_size };</div>
</div><!-- fragment --><div class="fragment"><div class="line">    memory::dims dec_dst_iter_dims = { dec_n_layers, 1, batch,</div>
<div class="line">        feature_size + feature_size };</div>
<div class="line">    memory::dims dec_dst_iter_noctx_dims</div>
<div class="line">            = { dec_n_layers, 1, batch, feature_size };</div>
</div><!-- fragment --><p>Decoder : create memory description Create memory descriptors for RNN data w/o specified layout </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> user_dec_wei_layer_md = memory::desc({ user_dec_wei_layer_dims },</div>
<div class="line">            memory::data_type::f32, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_dec_wei_iter_md = memory::desc({ user_dec_wei_iter_dims },</div>
<div class="line">            memory::data_type::f32, memory::format_tag::ldigo);</div>
<div class="line">    <span class="keyword">auto</span> user_dec_bias_md = memory::desc({ user_dec_bias_dims },</div>
<div class="line">            memory::data_type::f32, memory::format_tag::ldgo);</div>
<div class="line">    <span class="keyword">auto</span> dec_src_layer_md = memory::desc({ dec_src_layer_dims },</div>
<div class="line">            memory::data_type::u8, memory::format_tag::tnc);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_layer_md = memory::desc({ dec_dst_layer_dims },</div>
<div class="line">            memory::data_type::u8, memory::format_tag::tnc);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_md = memory::desc({ dec_dst_iter_dims },</div>
<div class="line">            memory::data_type::f32, memory::format_tag::ldnc);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_c_md = memory::desc({ dec_dst_iter_c_dims },</div>
<div class="line">            memory::data_type::f32, memory::format_tag::ldnc);</div>
</div><!-- fragment --><p>Decoder : Create memory </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> user_dec_wei_layer_memory = memory(</div>
<div class="line">            user_dec_wei_layer_md, cpu_engine, user_dec_wei_layer.data());</div>
<div class="line">    <span class="keyword">auto</span> user_dec_wei_iter_memory = memory(</div>
<div class="line">            user_dec_wei_iter_md, cpu_engine, user_dec_wei_iter.data());</div>
<div class="line">    <span class="keyword">auto</span> user_dec_bias_memory</div>
<div class="line">            = memory(user_dec_bias_md, cpu_engine, user_dec_bias.data());</div>
<div class="line">    <span class="keyword">auto</span> dec_src_layer_memory = memory(dec_src_layer_md, cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_layer_memory</div>
<div class="line">            = memory(dec_dst_layer_md, cpu_engine, dec_dst.data());</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_c_memory = memory(dec_dst_iter_c_md, cpu_engine);</div>
</div><!-- fragment --><p>Decoder : As mentioned above, we create a view without context out of the memory with context. </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> dec_dst_iter_memory = memory(dec_dst_iter_md, cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> dec_dst_iter_noctx_md = dec_dst_iter_md.submemory_desc(</div>
<div class="line">            dec_dst_iter_noctx_dims, { 0, 0, 0, 0, 0 });</div>
</div><!-- fragment --><p>Decoder : Create memory for input data and use reorders to quantize values to int8 </p>
<div class="fragment"><div class="line">    <span class="keyword">auto</span> dec_wei_layer_memory</div>
<div class="line">            = memory(dec_ctx_prim_desc.weights_layer_desc(), cpu_engine);</div>
<div class="line">    <span class="keyword">auto</span> dec_wei_layer_reorder_pd = reorder::primitive_desc(</div>
<div class="line">            user_dec_wei_layer_memory, dec_wei_layer_memory, attr);</div>
<div class="line">    reorder(dec_wei_layer_reorder_pd)</div>
<div class="line">            .execute(s, user_dec_wei_layer_memory, dec_wei_layer_memory);</div>
</div><!-- fragment --><p><b>Execution</b></p>
<p>run encoder (1 stream) </p>
<div class="fragment"><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> p = 0; p &lt; encoder_net.size(); ++p)</div>
<div class="line">            encoder_net.at(p).execute(s, encoder_net_args.at(p));</div>
</div><!-- fragment --><p>we compute the weighted annotations once before the decoder </p>
<div class="fragment"><div class="line">        compute_weighted_annotations(weighted_annotations.data(),</div>
<div class="line">                src_seq_length_max, batch, feature_size,</div>
<div class="line">                user_weights_annotation.data(),</div>
<div class="line">                (<span class="keywordtype">float</span> *)enc_dst_layer_memory.get_data_handle());</div>
</div><!-- fragment --><p>precompute compensation for s8u8s32 gemm in compute attention </p>
<div class="fragment"><div class="line">        compute_sum_of_rows(user_weights_attention_src_layer.data(),</div>
<div class="line">                feature_size, feature_size, weights_attention_sum_rows.data());</div>
</div><!-- fragment --><p>We initialize src_layer to the embedding of the end of sequence character, which are assumed to be 0 here </p>
<div class="fragment"><div class="line">        memset(dec_src_layer_memory.get_data_handle(), 0,</div>
<div class="line">                dec_src_layer_memory.get_desc().get_size());</div>
</div><!-- fragment --><p>From now on, src points to the output of the last iteration</p>
<p>Compute attention context vector into the first layer src_iter </p>
<div class="fragment"><div class="line">            compute_attention(src_att_iter_handle, src_seq_length_max, batch,</div>
<div class="line">                    feature_size, user_weights_attention_src_layer.data(),</div>
<div class="line">                    weights_attention_scale, weights_attention_sum_rows.data(),</div>
<div class="line">                    src_att_layer_handle, data_scale, data_shift,</div>
<div class="line">                    (uint8_t *)enc_bidir_dst_layer_memory.get_data_handle(),</div>
<div class="line">                    weighted_annotations.data(),</div>
<div class="line">                    user_weights_alignments.data());</div>
</div><!-- fragment --><p>copy the context vectors to all layers of src_iter </p>
<div class="fragment"><div class="line">            copy_context(src_att_iter_handle, dec_n_layers, batch,</div>
<div class="line">                    feature_size);</div>
</div><!-- fragment --><p>run the decoder iteration </p>
<div class="fragment"><div class="line">            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> p = 0; p &lt; decoder_net.size(); ++p)</div>
<div class="line">                decoder_net.at(p).execute(s, decoder_net_args.at(p));</div>
</div><!-- fragment --><p>Move the handle on the src/dst layer to the next iteration </p>
<div class="fragment"><div class="line">            <span class="keyword">auto</span> dst_layer_handle</div>
<div class="line">                    = (uint8_t *)dec_dst_layer_memory.get_data_handle();</div>
<div class="line">            dec_src_layer_memory.set_data_handle(dst_layer_handle);</div>
<div class="line">            dec_dst_layer_memory.set_data_handle(</div>
<div class="line">                    dst_layer_handle + batch * feature_size);</div>
</div><!-- fragment --></div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>