<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.5"/>
<title>Intel(R) MKL-DNN: A Performance Library for Deep Learning</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.5 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">A Performance Library for Deep Learning </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN) is an open source performance library for Deep Learning (DL) applications intended for acceleration of DL frameworks on Intel(R) architecture. Intel MKL-DNN includes highly vectorized and threaded building blocks for implementation of convolutional neural networks (CNN) with C and C++ interfaces. This project is created to help DL community innovate on Intel(R) processors.</p>
<p>The library supports the most commonly used primitives necessary to accelerate bleeding edge image recognition topologies, including AlexNet* and VGG*. The primitives include convolution, inner product, pooling, normalization, and activation primitives with support for forward (scoring or inference) operations. This release includes the following classes of functions:</p>
<ul>
<li>Convolution: direct batched convolution</li>
<li>Inner Product</li>
<li>Pooling: maximum</li>
<li>Normalization: local response normalization across channels (LRN)</li>
<li>Activation: rectified linear unit neuron activation (ReLU)</li>
<li>Data manipulation: reorder (multi-dimensional transposition/conversion)</li>
</ul>
<p>Intel MKL DNN primitives implement a plain C application programming interface (API) that can be used in the existing C/C++ DNN frameworks, as well as in custom DNN applications.</p>
<h2>Programming Model</h2>
<p>While in Intel MKL-DNN model, primitives have other primitives as inputs, outputs are memory primitives only. This feature enables reconstructing the graph of computations at run time.</p>
<h3>Basic Terminology</h3>
<p>Intel MKL-DNN operates on the following main objects:</p>
<ul>
<li><b>Primitive</b> - any operation: convolution, data format reorder, and even memory. Primitives can have other primitives as inputs, but can have only memory primitives as outputs.</li>
<li><b>Engine</b> - an execution device. Currently the only supported engine is CPU. Every primitive is mapped to a specific engine.</li>
<li><b>Stream</b> - an execution context: you submit primitives to a stream and wait for their completion. Primitives submitted to a stream may have different engines. Stream also tracks dependencies between the primitives.</li>
</ul>
<p>A typical workflow is the following: create a set of primitives to run, push them to a stream all at once or one-by-one, and wait for the completion.</p>
<h3>Creating Primitives</h3>
<p>To create a primitive, follow these steps:</p>
<ol type="1">
<li>Create a logical description of the operation in a descriptor such as a memory descriptor or convolution descriptor.</li>
<li>Create a description of the primitive to perform the operation. The description defines all the necessary details, such as descriptions of inputs and outputs.</li>
<li>Create an instance of a primitive and specify other primitives as inputs and outputs.</li>
</ol>
<p>These steps reflect the following levels of abstraction:</p>
<ul>
<li><b>Operation/memory descriptor</b> - a high-level description with logical parameters of an operation/memory. For example: the description of a convolution operation contains parameters such as sizes, strides, propagation type, and so on. A memory description contains dimensions, precision, and format of the data layout in memory. The memory format can be set to <code>any</code>, which means that it is not yet defined. This format is used to enable primitives choose the memory format for optimal performance. An operation/memory descriptor is a lightweight structure, which does not allocate any additional resources.</li>
<li><b>Primitive descriptor</b> - a complete description of a primitive that contains an operation descriptor, descriptors of primitive inputs and outputs, and the target engine. Permits future API extensions to enable querying the descriptor for estimated performance, memory consumptions, and so on. A primitive descriptor is also a lightweight structure.</li>
<li><b>Primitive</b> - a specific instance of a primitive created using the corresponding primitive descriptor. A primitive structure contains pointers to input primitives and output memory. Creation of a primitive is a potentially expensive operation because when a primitive is created, Intel MKL-DNN allocates resources that are needed to execute the primitive.</li>
</ul>
<h3>Auxiliary Types</h3>
<ul>
<li><b>Tensor</b> - a data description that contains the number of dimensions the data has and the dimensions themselves.</li>
<li><b>Primitive_at</b> - a structure that contains a primitive and an index. This structure specifies which output of the primitive to use as an input for another primitive.</li>
</ul>
<h3>C++ API Example</h3>
<p>The repository contains an example of how to build a neural network topology block that consists of convolution, ReLU, LRN, and pooling. Let's go through it step by step:</p>
<ol type="1">
<li>Initialize a CPU engine. The last parameter stands for the index of the engine. <div class="fragment"><div class="line"><span class="keyword">auto</span> cpu_engine = <a class="code" href="structmkldnn_1_1engine.html">mkldnn::engine</a>(<a class="code" href="group__cpp__api__memory.html#gga81bcf1ea92d7f98852a2c3e187825de6a7e33e884a6d7eb40a73125557b14a7a7">mkldnn::engine::cpu</a>, 0);</div>
</div><!-- fragment --></li>
<li>Create a vector of primitives that represents the net. <div class="fragment"><div class="line">std::vector&lt;mkldnn::primitive&gt; net;</div>
</div><!-- fragment --></li>
<li>Allocate input data and create a tensor structure that describes it. <div class="fragment"><div class="line">std::vector&lt;float&gt; src(2 * 3 * 227 * 227);</div>
<div class="line">mkldnn::tensor::dims conv_src_dims = {2, 3, 227, 227};</div>
</div><!-- fragment --></li>
<li>Create two memory descriptors: one for data in a user format, and one for the convolution input. Choose <code>nchw</code> (minibatch-channels-height-width) format for user data and the wildcard <code>any</code> for the convolution data format. <code>any</code> enables the convolution primitive to choose the data format that is most suitable for its input parameters (convolution kernel sizes, strides, padding, and so on). If the resulting format is different from <code>nchw</code>, user data needs to be transformed to the format required for the convolution. <div class="fragment"><div class="line"><span class="keyword">auto</span> user_src_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">mkldnn::memory::desc</a>({conv_src_dims},</div>
<div class="line">    mkldnn::memory::precision::f32, mkldnn::memory::format::nchw);</div>
<div class="line"><span class="keyword">auto</span> conv_src_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">mkldnn::memory::desc</a>({conv_src_dims},</div>
<div class="line">    mkldnn::memory::precision::f32, mkldnn::memory::format::any);</div>
</div><!-- fragment --></li>
<li>Create a convolution descriptor by specifying the algorithm, propagation kind, shapes of input, weights, bias, and output, and convolution strides, padding, and padding kind. <div class="fragment"><div class="line"><span class="keyword">auto</span> conv_desc = mkldnn::convolution::desc(</div>
<div class="line">    <a class="code" href="group__cpp__api__memory.html#ggaeb087eae78f70a4d249a90aefa165cf8a064cbe5d8f2575433bfaaaef8937f369">mkldnn::prop_kind::forward</a>, mkldnn::convolution::direct,</div>
<div class="line">    conv_src_md, <span class="comment">/* format::any used here to let convolution choose a format */</span></div>
<div class="line">    conv_weights_md, conv_bias_md, conv_dst_md,</div>
<div class="line">    {1, 1}, {0, 0}, <a class="code" href="group__cpp__api__memory.html#ggaa1ff931b28e0a90473ad5bddd21c60fcafbabef80df01bc0a5636d0ca9189355d">mkldnn::padding_kind::zero</a>);</div>
</div><!-- fragment --></li>
<li>Create a descriptor of the convolution primitive. Once created, this descriptor has specific formats instead of any wildcard formats specified in the convolution descriptor. <div class="fragment"><div class="line"><span class="keyword">auto</span> conv_pd = mkldnn::convolution::primitive_desc(conv_desc, cpu_engine);</div>
</div><!-- fragment --></li>
<li>Create a memory primitive that contains user data and check whether the user data format differs from the format that the convolution requires. In the case of differences, create a reorder primitive that transforms the user data to the convolution format and add it to the net. <div class="fragment"><div class="line"><span class="keyword">auto</span> user_src_memory_descriptor</div>
<div class="line">    = <a class="code" href="structmkldnn_1_1memory_1_1primitive__desc.html">mkldnn::memory::primitive_desc</a>(user_src_md, engine);</div>
<div class="line"></div>
<div class="line"><span class="keyword">auto</span> user_src_memory = <a class="code" href="structmkldnn_1_1memory.html">mkldnn::memory</a>(user_src_memory_descriptor, src);</div>
<div class="line"></div>
<div class="line"><span class="comment">/* Check whether a reorder is needed  */</span></div>
<div class="line"><span class="keyword">auto</span> conv_input = user_src_memory;</div>
<div class="line"><span class="keywordflow">if</span> (<a class="code" href="structmkldnn_1_1memory_1_1primitive__desc.html">mkldnn::memory::primitive_desc</a>(conv_pd.data.src_primitive_desc)</div>
<div class="line">        != user_src_memory_descriptor) {</div>
<div class="line">    <span class="comment">/* Yes, it is needed */</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">/* Convolution primitive descriptor contains the descriptor of a memory</span></div>
<div class="line"><span class="comment">     * primitive it requires as input. Because a pointer to the allocated</span></div>
<div class="line"><span class="comment">     * memory is not specified, Intel MKL-DNN allocates the memory. */</span></div>
<div class="line">    <span class="keyword">auto</span> conv_src_memory = <a class="code" href="structmkldnn_1_1memory.html">mkldnn::memory</a>(conv_pd.data.src_primitive_desc);</div>
<div class="line"></div>
<div class="line">    <span class="comment">/* create a reorder between data, make it an input for the convolution */</span></div>
<div class="line">    conv_input = <a class="code" href="structmkldnn_1_1reorder.html">mkldnn::reorder</a>(user_src_memory, conv_src_memory)</div>
<div class="line"></div>
<div class="line">    <span class="comment">/* put the reorder in the net */</span></div>
<div class="line">    net.push_back(conv_input);</div>
<div class="line">}</div>
</div><!-- fragment --></li>
<li>Create a convolution primitive and add it to the net. <div class="fragment"><div class="line"><span class="comment">/* Note that the conv_input primitive (whether it be a memory or a reorder)</span></div>
<div class="line"><span class="comment"> * is an input dependency for the convolution primitive, which means that the</span></div>
<div class="line"><span class="comment"> * convolution primitive will not be executed before the data is ready. */</span></div>
<div class="line"><span class="keyword">auto</span> conv = mkldnn::convolution(conv_pd, conv_input, conv_weights_memory,</div>
<div class="line">        conv_user_bias_memory, conv_dst_memory);</div>
<div class="line">net.push_back(conv);</div>
</div><!-- fragment --></li>
<li>Finally, create a stream, submit all the primitives, and wait for completion. <div class="fragment"><div class="line"><a class="code" href="structmkldnn_1_1stream.html">mkldnn::stream</a>().<a class="code" href="group__cpp__api__memory.html#ga018e38932cc072568a48015f55fbe798">submit</a>(net).<a class="code" href="group__cpp__api__memory.html#ga577fe98393390dc1ba646266d57566e2">wait</a>();</div>
</div><!-- fragment --></li>
</ol>
<p><a class="el" href="legal_information.html">Legal Information</a> </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.5
</small></address>
</body>
</html>
