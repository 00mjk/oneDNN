<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.5"/>
<title>Intel(R) MKL-DNN: Data Types</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)
   &#160;<span id="projectnumber">0.95.0</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.5 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Data Types </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Intel MKL-DNN functionality supports a number of numerical data types. IEEE single precision floating point (fp32) is considered to be the golden standard in deep learning applications and is supported in all the library functions. The purpose of low precision data types support is to improve performance of compute intensive operations, such as convolutions, inner product, and recurrent neural network cells in comparison to fp32.</p>
<table class="doxtable">
<tr>
<th align="left">Data type </th><th align="left">Description  </th></tr>
<tr>
<td align="left">fp32 </td><td align="left"><a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format#IEEE_754_single-precision_binary_floating-point_format:_binary32">IEEE single precision floating point</a> </td></tr>
<tr>
<td align="left">bf16 </td><td align="left"><a href="https://software.intel.com/en-us/download/bfloat16-hardware-numerics-definition">non-IEEE 16-bit floating point</a> </td></tr>
<tr>
<td align="left">fp16 </td><td align="left"><a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format#IEEE_754_half-precision_binary_floating-point_format:_binary16">IEEE half precision floating point</a> </td></tr>
<tr>
<td align="left">s8/u8 </td><td align="left">signed/unsigned 8-bit integer </td></tr>
</table>
<h2>Inference and Training</h2>
<p>Intel MKL-DNN supports training and inference with the following data types:</p>
<table class="doxtable">
<tr>
<th align="left">Usage mode </th><th align="left">CPU </th><th align="left">GPU  </th></tr>
<tr>
<td align="left">Inference </td><td align="left">fp32, bfp16, s8/u8 </td><td align="left">fp32, fp16 </td></tr>
<tr>
<td align="left">Training </td><td align="left">fp32, bfp16 </td><td align="left">fp32 </td></tr>
</table>
<p>Note, that using lower precision arithmetic requires changes in the deep learning model implementation. See topics for the corresponding data types for the details:</p>
<ul>
<li><a class="el" href="dev_guide_inference_int8.html">Int8 Inference</a><ul>
<li><a class="el" href="dev_guide_attributes_quantization.html">Primitive Attributes: Quantization</a></li>
</ul>
</li>
<li><a class="el" href="dev_guide_training_bfp16.html">bfp16 Training</a></li>
</ul>
<p>Individual primitives may have additional limitations with respect to data type support based on the precision requirements. The list of data types supported by each primitive is included into corresponding sections of the developer guide.</p>
<h2>Hardware Limitations</h2>
<p>While all the platforms Intel MKL-DNN supports have hardware acceleration for fp32 arithmetics, that is not the case for other data types. Considering that performance is the main purpose of the low precision data types support, Intel MKL-DNN implements this functionality only for the platforms that have hardware acceleration for these data types. The table below summarizes the current support matrix:</p>
<table class="doxtable">
<tr>
<th align="left">Data type </th><th align="left">CPU </th><th align="left">GPU  </th></tr>
<tr>
<td align="left">fp32 </td><td align="left">any </td><td align="left">any </td></tr>
<tr>
<td align="left">bfloat16 </td><td align="left">Intel(R) DL-Boost with bfloat16 </td><td align="left">not supported </td></tr>
<tr>
<td align="left">fp16 </td><td align="left">not supported </td><td align="left">any </td></tr>
<tr>
<td align="left">s8, u8 </td><td align="left">Intel(R) AVX512, Intel DL-Boost </td><td align="left">not supported </td></tr>
</table>
<dl class="section note"><dt>Note</dt><dd>Intel MKL-DNN can simulate the blfoat16 data type on CPUs with Intel(R) AVX512 BW. The performance of primitives in this case is approximately 3-4x times lower than the corresponding f32. The primary goal is to allow users to try using bfloat16 before the actual HW will become available. <hr/>
</dd></dl>
<p><a class="el" href="legal_information.html">Legal information</a> </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.5
</small></address>
</body>
</html>
